{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e76684-0e8b-49ce-801a-ee7d9c2e0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3c085e-3707-4a6d-a220-6e1599096c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87909941-ef6a-4ae0-94bc-29f47afe2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27,27), dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd67900-66a0-4bdc-bc1c-70d8b1e1d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0334e2e6-bb3c-4b77-9d7c-86f274f817eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e82f403-6cab-4f15-9408-4984bea10145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p /= p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8449b0-256b-4005-b1d9-3e13feaaff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()  #here +1 to N will make sure that there are no 0 values in our matrix that we have built. This is also called as model smoothing.\n",
    "P /= P.sum(1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15120c3a-57a6-4abb-90c4-23a02578cafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p, num_samples= 1, replacement = True, generator = g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99990d62-5f76-491a-b52c-43499fe82fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4544)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood = 0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        N[ix1, ix2] += 1\n",
    "\n",
    "nll = -log_likelihood/n              # average negative log likelihood\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405eda2-f3d4-461c-b2d9-593187a61332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is a neural network performing the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4199a50a-97b7-41e8-8dbe-db19a3dab811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of examples or bigrams is:  228146\n"
     ]
    }
   ],
   "source": [
    "#Creating a dataset for neural network\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(f'The total number of examples or bigrams is:  {num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7918e7a6-9684-49c5-9aff-6cac7246a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c8c51e-cc9c-4458-a689-6e3979762cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Randomly initialize 27 neurons' weights. Each neuron receives 27 inputs.\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator = g, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f3c5fa1-9c54-4c38-85ac-fa086d0e71d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4726529121398926\n",
      "2.4724340438842773\n",
      "2.4722201824188232\n",
      "2.472010850906372\n",
      "2.4718058109283447\n",
      "2.4716053009033203\n",
      "2.471409320831299\n",
      "2.471216917037964\n",
      "2.4710283279418945\n",
      "2.470843553543091\n",
      "2.4706625938415527\n",
      "2.4704854488372803\n",
      "2.4703118801116943\n",
      "2.4701414108276367\n",
      "2.4699742794036865\n",
      "2.4698104858398438\n",
      "2.4696500301361084\n",
      "2.469492197036743\n",
      "2.4693377017974854\n",
      "2.4691858291625977\n",
      "2.4690372943878174\n",
      "2.468891143798828\n",
      "2.468747615814209\n",
      "2.46860671043396\n",
      "2.468468427658081\n",
      "2.468332529067993\n",
      "2.4681990146636963\n",
      "2.4680681228637695\n",
      "2.4679393768310547\n",
      "2.4678127765655518\n",
      "2.46768856048584\n",
      "2.4675662517547607\n",
      "2.4674463272094727\n",
      "2.467327833175659\n",
      "2.467211961746216\n",
      "2.467097759246826\n",
      "2.4669857025146484\n",
      "2.4668753147125244\n",
      "2.466766357421875\n",
      "2.4666597843170166\n",
      "2.466554641723633\n",
      "2.4664509296417236\n",
      "2.4663491249084473\n",
      "2.4662492275238037\n",
      "2.4661505222320557\n",
      "2.4660532474517822\n",
      "2.4659576416015625\n",
      "2.4658634662628174\n",
      "2.4657704830169678\n",
      "2.465679407119751\n",
      "2.4655895233154297\n",
      "2.465500593185425\n",
      "2.4654135704040527\n",
      "2.465327501296997\n",
      "2.465242624282837\n",
      "2.4651591777801514\n",
      "2.4650766849517822\n",
      "2.4649956226348877\n",
      "2.4649155139923096\n",
      "2.464836597442627\n",
      "2.46475887298584\n",
      "2.464682102203369\n",
      "2.464606285095215\n",
      "2.464531660079956\n",
      "2.4644579887390137\n",
      "2.464385509490967\n",
      "2.4643139839172363\n",
      "2.464243173599243\n",
      "2.4641737937927246\n",
      "2.464104652404785\n",
      "2.464036703109741\n",
      "2.4639699459075928\n",
      "2.4639039039611816\n",
      "2.4638383388519287\n",
      "2.463773727416992\n",
      "2.463710308074951\n",
      "2.4636473655700684\n",
      "2.463585376739502\n",
      "2.4635238647460938\n",
      "2.463463306427002\n",
      "2.4634037017822266\n",
      "2.4633448123931885\n",
      "2.4632863998413086\n",
      "2.463228702545166\n",
      "2.4631717205047607\n",
      "2.463115692138672\n",
      "2.463059902191162\n",
      "2.4630050659179688\n",
      "2.4629504680633545\n",
      "2.4628970623016357\n",
      "2.462843894958496\n",
      "2.4627914428710938\n",
      "2.462739944458008\n",
      "2.462688684463501\n",
      "2.4626379013061523\n",
      "2.462587594985962\n",
      "2.462538242340088\n",
      "2.462489128112793\n",
      "2.4624407291412354\n",
      "2.462393045425415\n"
     ]
    }
   ],
   "source": [
    "#Gradient Descent\n",
    "for k in range(100):\n",
    "\n",
    "    #Forward Pass\n",
    "    xenc = F.one_hot(xs, num_classes = 27).float() #input to the network: One Hot Encoding\n",
    "    logits = xenc @ W      #Predict log-counts\n",
    "    counts = logits.exp()  #Equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims = True) #probabilites for next character\n",
    "    #the last two lines where we have calculated counts and probs are called 'Softmax'.\n",
    "    \n",
    "    loss = -probs[torch.arange(num), ys].log().mean()  #Negative log likelihood\n",
    "    print(loss.item())\n",
    "\n",
    "    #Backward Pass\n",
    "    W.grad = None # Gradient is set to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcdb6df4-8fa1-4a0d-af6d-3eef65dbd621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "prelay.\n",
      "a.\n",
      "nn.\n"
     ]
    }
   ],
   "source": [
    "#Finally sample from the neural network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes = 27).float()\n",
    "        logits = xenc @ W #Predict log-counts\n",
    "        counts = logits.exp() #counts is equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims = True) #Probabilities for next character\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples= 1, replacement = True, generator = g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b936e-e7c2-4d7b-a24a-864150b405d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
